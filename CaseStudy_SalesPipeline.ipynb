{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_ZNUZmAe0GB",
    "outputId": "6ae13451-f593-40d7-af03-f247d187d64b"
   },
   "outputs": [],
   "source": [
    "# Install required libraries for economic data retrieval and synthetic data generation\n",
    "!pip install fredapi\n",
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I75ALjlbfHGI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly data already up to date. Latest month: June 2025\n"
     ]
    }
   ],
   "source": [
    "# Importing essential libraries for data processing, date handling, and logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from fredapi import Fred\n",
    "import os\n",
    "import logging\n",
    "from faker import Faker\n",
    "\n",
    "# Define global constants and configuration values\n",
    "FRED_API_KEY = '18ff54ec62ffdfc7b64cad1a2a2e7b7c' #update with your fred api key\n",
    "DATA_PATH = '../Downloads/'  #update with the data path where you want to save the file\n",
    "CATEGORY = 'Shampoo'\n",
    "NUM_PRODUCTS = 50\n",
    "MASTER_FILE = 'US_Historical_Sales.csv'\n",
    "\n",
    "# Initialize Faker instance for dummy values\n",
    "fake = Faker()\n",
    "\n",
    "# Set up logging configuration and ensuring log file exists\n",
    "LOG_FILE = os.path.join(DATA_PATH, 'data_check_log.txt')\n",
    "CRITICAL_FIELDS = ['week_start_date', 'product_id', 'units_sold', 'price', 'revenue']\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "if not os.path.isfile(LOG_FILE):\n",
    "    with open(LOG_FILE, 'w') as f:\n",
    "        f.write(\"=== Data Integrity Log Started ===\\n\")\n",
    "\n",
    "log_formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "file_handler = logging.FileHandler(LOG_FILE, mode='a')\n",
    "file_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(file_handler)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Helper to log and print\n",
    "def log_and_print(message, level='info'):\n",
    "    print(message)\n",
    "    getattr(logger, level)(message)\n",
    "    \n",
    "# Function to return seasonal adjustment factor based on the month\n",
    "def seasonal_factor(date):\n",
    "    if date.month in [6, 7, 8]:\n",
    "        return 1.2\n",
    "    elif date.month in [11, 12]:\n",
    "        return 1.5\n",
    "    return 1.0\n",
    "\n",
    "# Function to generate synthetic sales data for all products over the date range\n",
    "def generate_synthetic_sales(start_date, end_date):\n",
    "    sundays = pd.date_range(start=start_date, end=end_date, freq='W-SUN')\n",
    "    products = [{'product_id': f'P{i:03}', 'product_name': f\"{CATEGORY} Variant {i}\"} for i in range(1, NUM_PRODUCTS + 1)]\n",
    "\n",
    "    records = []\n",
    "    for week_start in sundays:\n",
    "        for product in products:\n",
    "            base_price = round(np.random.uniform(4.0, 15.0), 2)\n",
    "            discount = np.random.choice([0, 5, 10, 15, 20], p=[0.5, 0.2, 0.15, 0.1, 0.05])\n",
    "            price_after_discount = base_price * (1 - discount / 100)\n",
    "            base_units = np.random.randint(20, 100)\n",
    "            seasonal_boost = seasonal_factor(week_start)\n",
    "            discount_boost = 1 + (discount / 100) * 1.5\n",
    "            units_sold = int(base_units * seasonal_boost * discount_boost)\n",
    "            revenue = round(units_sold * price_after_discount, 2)\n",
    "\n",
    "            records.append({\n",
    "                'week_start_date': week_start,\n",
    "                'product_id': product['product_id'],\n",
    "                'product_name': product['product_name'],\n",
    "                'units_sold': units_sold,\n",
    "                'price': base_price,\n",
    "                'discount_percentage': discount,\n",
    "                'revenue': revenue,\n",
    "                'region': 'US'\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Function to fetch weekly gas prices and CPI data from the FRED API\n",
    "def fetch_latest_economic_indicators(start_date):\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "    \n",
    "    # Fetch average weekly gas prices\n",
    "    gas_prices = fred.get_series('GASREGW')\n",
    "    gas_df = gas_prices.reset_index()\n",
    "    gas_df.columns = ['date', 'avg_gas_price']\n",
    "    gas_df['date'] = pd.to_datetime(gas_df['date'])\n",
    "    gas_df = gas_df.set_index('date').resample('W-SUN').mean().ffill().reset_index()\n",
    "\n",
    "    # Fetch Consumer Price Index data\n",
    "    cpi = fred.get_series('CPIAUCSL')\n",
    "    cpi_df = cpi.reset_index()\n",
    "    cpi_df.columns = ['date', 'cpi']\n",
    "    cpi_df['date'] = pd.to_datetime(cpi_df['date'])\n",
    "    cpi_df = cpi_df.set_index('date').resample('W-SUN').ffill().reset_index()\n",
    "\n",
    "    return gas_df, cpi_df\n",
    "\n",
    "# Function to merges gas prices and CPI data to sales records\n",
    "def merge_sales_with_economics(df_sales, gas_df, cpi_df):\n",
    "    df_sales = df_sales.merge(gas_df, left_on=\"week_start_date\", right_on=\"date\", how=\"left\")\n",
    "    df_sales = df_sales.merge(cpi_df, left_on=\"week_start_date\", right_on=\"date\", how=\"left\")\n",
    "    df_sales.drop(columns=['date_x', 'date_y'], errors='ignore', inplace=True)\n",
    "    df_sales['avg_gas_price'] = df_sales['avg_gas_price'].fillna(method='ffill')\n",
    "    df_sales['cpi'] = df_sales['cpi'].fillna(method='ffill')\n",
    "    return df_sales\n",
    "\n",
    "# Main function that controls the workflow: data creation, enrichment, and update\n",
    "def main():\n",
    "    today = datetime.today()\n",
    "    master_path = os.path.join(DATA_PATH, MASTER_FILE)\n",
    "\n",
    "    # Step 1: Generate master file if it does not already exist\n",
    "    if not os.path.isfile(master_path):\n",
    "        logging.info(\"Master file not found. Generating synthetic data for 2024...\")\n",
    "        start = datetime(2024, 1, 1)\n",
    "        end = datetime(2024, 12, 31)\n",
    "        df_master = generate_synthetic_sales(start, end)\n",
    "        gas_df, cpi_df = fetch_latest_economic_indicators(start)\n",
    "        df_master = merge_sales_with_economics(df_master, gas_df, cpi_df)\n",
    "        df_master.to_csv(master_path, index=False)\n",
    "        logging.info(\"Master sales file created and saved.\")\n",
    "    else:\n",
    "        df_master = pd.read_csv(master_path, parse_dates=['week_start_date'])\n",
    "\n",
    "    # Step 2: Identify next month to generate data (based on existing files)\n",
    "    existing_months = [f for f in os.listdir(DATA_PATH) if f.startswith(\"US_Monthly_Sales_\") and f.endswith(\".csv\")]\n",
    "    existing_dates = []\n",
    "    for fname in existing_months:\n",
    "        try:\n",
    "            dt = datetime.strptime(fname.replace(\"US_Monthly_Sales_\", \"\").replace(\".csv\", \"\"), \"%B_%Y\")\n",
    "            existing_dates.append(dt)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    last_generated_month = max(existing_dates) if existing_dates else datetime(2024, 12, 1)\n",
    "    next_month = last_generated_month + pd.offsets.MonthBegin(1)\n",
    "\n",
    "    # Check if monthly data is already current\n",
    "    if next_month > today.replace(day=1):\n",
    "        print(f\"Monthly data already up to date. Latest month: {last_generated_month.strftime('%B %Y')}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Generate synthetic data for the next month\n",
    "    start = next_month\n",
    "    end = (start + pd.offsets.MonthEnd(0)).to_pydatetime()\n",
    "    df_monthly = generate_synthetic_sales(start, end)\n",
    "    gas_df, cpi_df = fetch_latest_economic_indicators(start)\n",
    "    df_monthly = merge_sales_with_economics(df_monthly, gas_df, cpi_df)\n",
    "\n",
    "    # Save monthly file\n",
    "    monthly_file = os.path.join(DATA_PATH, f\"US_Monthly_Sales_{next_month.strftime('%B_%Y')}.csv\")\n",
    "    df_monthly.to_csv(monthly_file, index=False)\n",
    "    logging.info(f\"Monthly sales file generated and saved: {monthly_file}\")\n",
    "\n",
    "    # Step 4: Update master file by removing existing data for the same month and appending the new data\n",
    "    month_str = next_month.strftime('%Y-%m')\n",
    "    df_master = df_master[~df_master['week_start_date'].dt.to_period('M').astype(str).eq(month_str)]\n",
    "    df_updated = pd.concat([df_master, df_monthly], ignore_index=True)\n",
    "    df_updated.to_csv(master_path, index=False)\n",
    "    logging.info(f\"Monthly sales for {next_month.strftime('%B %Y')} merged and saved to master database.\")\n",
    "    print(f\"Merging complete: Monthly sales for {next_month.strftime('%B %Y')} successfully updated in master data.\")\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
